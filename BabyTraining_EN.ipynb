{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2hr7cWIsQHQ"
      },
      "outputs": [],
      "source": [
        "# https://huggingface.co/blog/how-to-train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO4EU4-8-81X",
        "outputId": "38349e50-4cad-4e5e-98dd-f350d69b411d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUtSYQU6vioc",
        "outputId": "6c16b54d-78ae-4248-ff3d-c3da9d3ba49a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import RobertaConfig\n",
        "from transformers import RobertaForMaskedLM\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from transformers import RobertaTokenizerFast\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import SequentialSampler\n",
        "from datasets import load_dataset\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAIzIbtQqB1K",
        "outputId": "0367a97a-52bc-45c1-921e-4b11c1bd262c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "y-bPbd4xOhvd"
      },
      "outputs": [],
      "source": [
        "ds = load_dataset(\"abisee/cnn_dailymail\", \"1.0.0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw8A7demSfjr",
        "outputId": "2dcff622-825e-4ba6-8af6-af05b9bfb652"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 287113\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 13368\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 11490\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eop6XEB2Stks",
        "outputId": "b88be1c1-d1a9-44c2-f1a0-4663aea19cfb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'article': 'LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter\\'s latest » . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.',\n",
              " 'highlights': \"Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday . Young actor says he has no plans to fritter his cash away . Radcliffe's earnings from first five Potter films have been held in trust fund .\",\n",
              " 'id': '42c027e4ff9730fbb3de84c1af0d2c506e41c3e4'}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "ds[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "YBsEMxclzlFs",
        "outputId": "13409cca-0654-477d-8f28-c006ad35aead"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(CNN)  -- The National Football League has indefinitely suspended Atlanta Falcons quarterback Michael Vick without pay, officials with the league said Friday. NFL star Michael Vick is set to appear in court Monday. A judge will have the final say on a plea deal. Earlier, Vick admitted to participating in a dogfighting ring as part of a plea agreement with federal prosecutors in Virginia. \"Your admitted conduct was not only illegal, but also cruel and reprehensible. Your team, the NFL, and NFL fans have all been hurt by your actions,\" NFL Commissioner Roger Goodell said in a letter to Vick. Goodell said he would review the status of the suspension after the legal proceedings are over. In papers filed Friday with a federal court in Virginia, Vick also admitted that he and two co-conspirators killed dogs that did not fight well. Falcons owner Arthur Blank said Vick\\'s admissions describe actions that are \"incomprehensible and unacceptable.\" The suspension makes \"a strong statement that conduct which tarnishes the good reputation of the NFL will not be tolerated,\" he said in a statement.  Watch what led to Vick\\'s suspension » . Goodell said the Falcons could \"assert any claims or remedies\" to recover $22 million of Vick\\'s signing bonus from the 10-year, $130 million contract he signed in 2004, according to The Associated Press. Vick said he would plead guilty to one count of \"Conspiracy to Travel in Interstate Commerce in Aid of Unlawful Activities and to Sponsor a Dog in an Animal Fighting Venture\" in a plea agreement filed at U.S. District Court in Richmond, Virginia. The charge is punishable by up to five years in prison, a $250,000 fine, \"full restitution, a special assessment and 3 years of supervised release,\" the plea deal said. Federal prosecutors agreed to ask for the low end of the sentencing guidelines. \"The defendant will plead guilty because the defendant is in fact guilty of the charged offense,\" the plea agreement said. In an additional summary of facts, signed by Vick and filed with the agreement, Vick admitted buying pit bulls and the property used for training and fighting the dogs, but the statement said he did not bet on the fights or receive any of the money won. \"Most of the \\'Bad Newz Kennels\\' operations and gambling monies were provided by Vick,\" the official summary of facts said. Gambling wins were generally split among co-conspirators Tony Taylor, Quanis Phillips and sometimes Purnell Peace, it continued. \"Vick did not gamble by placing side bets on any of the fights. Vick did not receive any of the proceeds from the purses that were won by \\'Bad Newz Kennels.\\' \" Vick also agreed that \"collective efforts\" by him and two others caused the deaths of at least six dogs. Around April, Vick, Peace and Phillips tested some dogs in fighting sessions at Vick\\'s property in Virginia, the statement said. \"Peace, Phillips and Vick agreed to the killing of approximately 6-8 dogs that did not perform well in \\'testing\\' sessions at 1915 Moonlight Road and all of those dogs were killed by various methods, including hanging and drowning. \"Vick agrees and stipulates that these dogs all died as a result of the collective efforts of Peace, Phillips and Vick,\" the summary said. Peace, 35, of Virginia Beach, Virginia; Phillips, 28, of Atlanta, Georgia; and Taylor, 34, of Hampton, Virginia, already have accepted agreements to plead guilty in exchange for reduced sentences. Vick, 27, is scheduled to appear Monday in court, where he is expected to plead guilty before a judge.  See a timeline of the case against Vick » . The judge in the case will have the final say over the plea agreement. The federal case against Vick focused on the interstate conspiracy, but Vick\\'s admission that he was involved in the killing of dogs could lead to local charges, according to CNN legal analyst Jeffrey Toobin. \"It sometimes happens -- not often -- that the state will follow a federal prosecution by charging its own crimes for exactly the same behavior,\" Toobin said Friday. \"The risk for Vick is, if he makes admissions in his federal guilty plea, the state of Virginia could say, \\'Hey, look, you admitted violating Virginia state law as well. We\\'re going to introduce that against you and charge you in our court.\\' \" In the plea deal, Vick agreed to cooperate with investigators and provide all information he may have on any criminal activity and to testify if necessary. Vick also agreed to turn over any documents he has and to submit to polygraph tests. Vick agreed to \"make restitution for the full amount of the costs associated\" with the dogs that are being held by the government. \"Such costs may include, but are not limited to, all costs associated with the care of the dogs involved in that case, including if necessary, the long-term care and/or the humane euthanasia of some or all of those animals.\" Prosecutors, with the support of animal rights activists, have asked for permission to euthanize the dogs. But the dogs could serve as important evidence in the cases against Vick and his admitted co-conspirators. Judge Henry E. Hudson issued an order Thursday telling the U.S. Marshals Service to \"arrest and seize the defendant property, and use discretion and whatever means appropriate to protect and maintain said defendant property.\" Both the judge\\'s order and Vick\\'s filing refer to \"approximately\" 53 pit bull dogs. After Vick\\'s indictment last month, Goodell ordered the quarterback not to report to the Falcons training camp, and the league is reviewing the case. Blank told the NFL Network on Monday he could not speculate on Vick\\'s future as a Falcon, at least not until he had seen \"a statement of facts\" in the case.  E-mail to a friend . CNN\\'s Mike Phelan contributed to this report.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "#the news article is in the article key\n",
        "ds[\"train\"][4][\"article\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "HdXu8pmJgx3f"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(ds[\"train\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w61eQ2VAhY3e",
        "outputId": "070d6ac9-adee-41b9-f11f-0343ce4ee411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 287113 entries, 0 to 287112\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   article     287113 non-null  object\n",
            " 1   highlights  287113 non-null  object\n",
            " 2   id          287113 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 6.6+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "bvSzB2achq7Y",
        "outputId": "74a15ebd-5588-424f-e893-717bec09cf41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "article       0\n",
              "highlights    0\n",
              "id            0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>article</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>highlights</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reducing the size of the dataset since the total would be way too big for this BabyLM\n",
        "df = df[:10000]"
      ],
      "metadata": {
        "id": "qXcqIlvCyIrc"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating sentences\n",
        "df_sent = df\n",
        "df_sent['sentences'] = [nltk.sent_tokenize(text) for text in df_sent['article']]"
      ],
      "metadata": {
        "id": "-DvJHTUeNDmQ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a single list of all the sentences in each article\n",
        "sentences = sum(df_sent['sentences'].tolist(), [])"
      ],
      "metadata": {
        "id": "caT1XB0BixdY"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text, punctuation_marks):\n",
        "    \"\"\"Remove the punctuation specified by the user, and return the same string without the unwanted characters.\n",
        "\n",
        "    Parameters:\n",
        "    - 'text': string to process and remove characters from.\n",
        "    - 'punctuation marks': characters to be removed, given in list format. It can be any number of characters.\"\"\"\n",
        "\n",
        "    for character in punctuation_marks: #iterating over the characters given in the parameter list 'punctuation_marks'\n",
        "        text = text.replace(character, '') #the characters given will be removed from the string by replacing them with empty strings ''\n",
        "    preprocessesed_text = text #assigning the variable text to a new variable so that it returns the text with all the instances of the punctuation marks removed.\n",
        "    return preprocessesed_text"
      ],
      "metadata": {
        "id": "uwUU3S5O3ZD_"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_sentences = []\n",
        "for sent in sentences:\n",
        "  cleaned = preprocess(sent,['\"']) #removing quotation marks so that the text is cleaner for the model\n",
        "  cleaned_sentences.append(cleaned)"
      ],
      "metadata": {
        "id": "bcy3KvRB3bP6"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cleaned_sentences[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXKyJUrO3oWG",
        "outputId": "dadcdb33-4e65-4299-922f-e2890c0e815a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him.\", 'Daniel Radcliffe as Harry Potter in Harry Potter and the Order of the Phoenix To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties.', \"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar, he told an Australian interviewer earlier this month.\", \"I don't think I'll be particularly extravagant.\", 'The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing each sentence in cleaned_sentences\n",
        "tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in cleaned_sentences]\n",
        "\n",
        "# Calculate the total number of tokens\n",
        "total_tokens = sum(len(tokens) for tokens in tokenized_sentences)\n",
        "\n",
        "print(f\"Total number of tokens: {total_tokens}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90zKcfzw7kN7",
        "outputId": "c017074a-ad66-47f4-a2af-5d4f7d966338"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of tokens: 7061584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "bnlRQdbQkAZN"
      },
      "outputs": [],
      "source": [
        "sequences = cleaned_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNisKd9xz0j0"
      },
      "outputs": [],
      "source": [
        "##Celonie's code starts here\n",
        "\n",
        "#train_filepath = 'data/ranked_sequences.csv'\n",
        "\n",
        "\n",
        "#ranked = pd.read_csv(train_filepath)\n",
        "#sequences = ranked['sequence'].tolist()\n",
        "\n",
        "#with open('combined.dev') as infile:\n",
        "#  devset = infile.read().split(\"\\n\")[:10000]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-Basc1I0xHd",
        "outputId": "057fdb98-2c19-4bcf-a4d6-32bc59cdc77e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "329883"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "len(sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "48_3PGqGlauE"
      },
      "outputs": [],
      "source": [
        "#split data into train and dev\n",
        "\n",
        "df_train, df_dev = train_test_split(sequences, test_size=0.15, random_state=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnaO30UXcnu6",
        "outputId": "7e8dd984-6966-437d-a431-a40a1696dea8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "280400"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "len(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## got until here 20/Sep"
      ],
      "metadata": {
        "id": "_tpgbrfLThVU"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mc0atPEjqYb8"
      },
      "outputs": [],
      "source": [
        "tokenizer_folder = 'tokenizer_folder'\n",
        "\n",
        "if not os.path.exists(tokenizer_folder):\n",
        "    os.mkdir(tokenizer_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLiZn11uurNY"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "tokenizer.train_from_iterator(df_train, vocab_size=52_000, min_frequency=2, show_progress=True, special_tokens=[\n",
        "    \"<s>\",\n",
        "    \"<pad>\",\n",
        "    \"</s>\",\n",
        "    \"<unk>\",\n",
        "    \"<mask>\",\n",
        "])\n",
        "\n",
        "# Save tokenizer\n",
        "tokenizer.save_model(tokenizer_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhHutYsoyAU5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Configuration for RoBERTa model\n",
        "config = RobertaConfig(\n",
        "    vocab_size=52_000,\n",
        "    max_position_embeddings=514,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=6,\n",
        "    type_vocab_size=1,\n",
        ")\n",
        "# Initialize model\n",
        "model = RobertaForMaskedLM(config=config)\n",
        "print('Num parameters: ',model.num_parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGymxT92yPTu"
      },
      "outputs": [],
      "source": [
        "# tokenizer_folder = 'tokenizer_folder'\n",
        "\n",
        "# Load tokenizer\n",
        "max_length = 512\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_folder, max_len=max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCd9hLauzYv2"
      },
      "outputs": [],
      "source": [
        "# create CustomDataset class\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.examples = []\n",
        "        self.mask = []\n",
        "\n",
        "        for example in data:\n",
        "            x=tokenizer.encode_plus(example, max_length = max_length, truncation=True, padding=True)\n",
        "            self.examples += [x.input_ids]\n",
        "            self.mask += [x.attention_mask]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return torch.tensor(self.examples[i])\n",
        "\n",
        "# create train and evaluation datasets\n",
        "train_dataset = CustomDataset(df_train, tokenizer)\n",
        "eval_dataset = CustomDataset(df_dev, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0OhTWkO1HhF"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define data collator\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B60fb9KTLRHz"
      },
      "outputs": [],
      "source": [
        "#adapted from https://github.com/MiuLab/FastMTL/blob/only3/custom_trainer.py\n",
        "\n",
        "# adapt get_train_dataloader function to supply DataLoader using SequentialSampler and shuffle=False to enforce curriculum learning\n",
        "\n",
        "from transformers.trainer import *\n",
        "def get_train_dataloader(self) -> DataLoader:\n",
        "    \"\"\"\n",
        "    Returns the training :class:`~torch.utils.data.DataLoader`.\n",
        "\n",
        "    Will use no sampler if :obj:`self.train_dataset` does not implement :obj:`__len__`, a random sampler (adapted\n",
        "    to distributed training if necessary) otherwise.\n",
        "\n",
        "    Subclass and override this method if you want to inject some custom behavior.\n",
        "    \"\"\"\n",
        "    if self.train_dataset is None:\n",
        "        raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
        "\n",
        "    return DataLoader(\n",
        "        self.train_dataset,\n",
        "        batch_size=self.args.train_batch_size,\n",
        "        sampler=SequentialSampler(self.train_dataset),\n",
        "        collate_fn=self.data_collator,\n",
        "        drop_last=self.args.dataloader_drop_last,\n",
        "        num_workers=self.args.dataloader_num_workers,\n",
        "        shuffle=False\n",
        "    )\n",
        "Trainer.get_train_dataloader = get_train_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTGGf-XP1UZf"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='model_folder',\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy = 'epoch',\n",
        "    num_train_epochs=5,\n",
        "    learning_rate=1e-4,\n",
        "    weight_decay=0.01,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    save_steps=8192,\n",
        "    save_total_limit=1,\n",
        "    #seed=10098,\n",
        "    max_steps=int(1269227 / batch_size)\n",
        ")\n",
        "# Create trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2X7bzHM2Dxb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}